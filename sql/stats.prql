prql target:sql.duckdb

let approx_count_distinct = column -> s"approx_count_distinct({column})"
let regexp_extract = column r -> s"regexp_extract({column}, {r})"
let row_to_json = name -> s"row_to_json({name})"
let month_trunc = name -> s"date_trunc('MONTH', {name})"

let relation_to_json = func r -> (
  from s=r
  aggregate {
    _to_json=s"row_to_json(s)"
  }
  aggregate {
    stat = s"json_group_array({_to_json})",
    name = s"'{r}'"
   }
)

let base = (
  from (read_parquet($1))
)

let base_with_extension = (
  from base
  select {
    extension = (regexp_extract path "\\.[0-9a-z]+$"),
    lines,
    size,
    skip_reason,
    hash
  }
)

let total_stats = (
  from base
  aggregate {
    total_files = count(s"*"),
    unique_files = approx_count_distinct(hash) | as bigint,
    total_size = sum(size) | as bigint,
    total_lines = sum(lines) | as bigint
  }
)

let extension_stats = (
  from base_with_extension
  group {extension = extension} (
    aggregate {
      total_files = count(s"*"),
      unique_files = approx_count_distinct(hash) | as bigint,
      total_lines = sum(lines) | as bigint,
      total_size = sum(size) | as bigint
    }
  )
  sort {-total_files}
  take 10
)

let base_binary_extension_stats = (
  from base_with_extension
  filter skip_reason == "binary"
  group {extension = extension} (
    aggregate {
      total_files = count(s"*"),
      unique_files = approx_count_distinct(hash) | as bigint,
      total_lines = sum(lines) | as bigint,
      total_size = sum(size) | as bigint
    }
  )
  sort {-total_size}
  take 10
)

let projects_by_files = (
  from base_with_extension
  group {project_name = project_name} (
    aggregate {
      total_files = count(s"*"),
      unique_files = approx_count_distinct(hash) | as bigint,
      total_lines = sum(lines) | as bigint,
      total_size = sum(size) | as bigint
    }
  )
  sort {-total_size}
  take 10
)

let skipped_files_stats = (
  from base_with_extension
  filter skip_reason != "binary"
  filter skip_reason != ""
  group {extension = extension} (
    aggregate {
      total_files = count(s"*"),
      unique_files = approx_count_distinct(hash) | as bigint,
      total_lines = sum(lines) | as bigint,
      total_size = sum(size) | as bigint
    }
  )
  sort {-total_files}
  take 10
)

let stats_over_time = (
  from base
  group {month = month_trunc(uploaded_on)} (
    aggregate {
      total_uploads = s"COUNT(DISTINCT {project_name})" | as bigint,
      project_releases = s"COUNT(DISTINCT {project_release})" | as bigint,
      project_version_releases = s"COUNT(DISTINCT ({project_name}, {project_version}))" | as bigint,
      total_files = s"count(*)" | as bigint,
      total_size = sum(size) | as bigint,
      total_lines = sum(lines) | as bigint,
      total_hours = s"date_diff('hours', min({uploaded_on}), max({uploaded_on}))",
      unique_files = approx_count_distinct(hash) | as bigint,
    }
  )
)



relation_to_json(total_stats)
append (relation_to_json extension_stats)
append (relation_to_json binary_extension_stats)
append (relation_to_json skipped_files_stats)
append (relation_to_json stats_over_time)
append (relation_to_json projects_by_files)